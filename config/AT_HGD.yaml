
OPTIONS:
    RAW: FALSE
    ADV: TRUE

HYPERPARAMETERS:
    BATCH_SIZE: 64
    EPOCHS: 30
    OPTIM:
        NAME: 'ADAM'
        LEARNING_RATE: 0.001
        WEIGHT_DECAY: 0
#     LEARNING_RATE: 0.001
#     MOMENTUM: null
#     NESTEROV: null
#     WEIGHT_DECAY: null
    PRINT_FREQ: 10

DATASET:
    NAME: 'CIFAR10'
#     TRAIN: FALSE
    CLASSES: 10
    DIR_PATH: 'datasets/'
    NORMALIZE: FALSE
    CROP: FALSE
    
ATTACK:
    NAME: "PGD"
    MAX_ITER: 1
    MOMENTUM: null
    # [CONSTANT(4), DYNAMIC(MAX_ITER), RANDOM_RANGE]
    EPSILON:
        TYPE: 'RANDOM'
        VALUE: null
        MIN: 0
        MAX: 17
    ALPHA:
        NAME: 'CONSTANT'
        DIVISOR: 1


MODELS:
    # Model used to generate adversarial examples (ATTACK model)
    TRAIN_MODEL:
        NAME: "HGD"
        TRAIN: TRUE
        PARALLEL: FALSE
        DENOISER_PATH: null
        SAVE_DIR: "chkpt/denoiser_pgd1/"
        TARGET:
            NAME: "WideResNet"
            DEPTH: 28
            WIDEN_FACTOR: 10
            DROP_RATE: 0
            PARALLEL: TRUE
            PRETRAINED: TRUE
            CHKPT_PATH: "chkpt/chkpt_scaled/chkpt_plain__model_best.pth.tar"
    
    # Model we are trying to fool
    ADV_MODEL:
        NAME: "WideResNet"
        DEPTH: 28
        WIDEN_FACTOR: 10
        DROP_RATE: 0
        PARALLEL: TRUE
        PRETRAINED: TRUE
        CHKPT_PATH: "chkpt/chkpt_scaled/chkpt_plain__model_best.pth.tar"

    
PATHS:
    ADV_MODEL_PATH: "chkpt/chkpt_scaled/chkpt_plain__model_best.pth.tar"
    THREAT_MODEL_PATH: "chkpt/chkpt_scaled/chkpt_plain__model_best.pth.tar"
    RESULTS_PATH: 'results/'